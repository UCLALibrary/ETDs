#!/bin/sh

# Process ETDs.
# Define various functions which will do discrete pieces of the processing.

###########################################################################
# Allow only one instance of this script to run;
# Exit if already running.
_exit_if_already_running() {
  MY_PID=$$
  MY_NAME=`basename $0`
  echo "Starting process ${MY_PID} for ${MY_NAME}..."
  OTHERS=`ps -ef | grep ${MY_NAME} | grep -v "sh -c" | grep -v grep | grep -v ${MY_PID} | wc -l`
  if [ ${OTHERS} -gt 0 ]; then
    echo "${MY_NAME} is already running - exiting this new instance"
    exit 1
  fi
}

###########################################################################
# Initialize script with configuration.
_initialize() {
  # Get full path to script, to use as base
  # Assumes scripts are in BASE/bin, config in BASE/config, etc.
  DIR=`dirname $0`
  BASE=`(cd $DIR/.. && pwd)`

  # Get config info
  CONFIG=${BASE}/config
  . ${CONFIG}/*

  # Make new files and directories read/write for owner/group, no access for others.
  umask 007

  _check_directories
}

###########################################################################
# Make sure local directories exist and have correct permissions.
_check_directories() {
  for DIR in $FILES_INCOMING $FILES_PENDING $FILES_ARCHIVE; do
    if [ ! -d ${DIR} ]; then
      echo "Creating ${DIR}..."
      mkdir -p ${DIR}
    fi
  done
}

###########################################################################
# Get new files from sftp server
_get_incoming_files() {
  (
    echo "ls -l ${UCLA_SFTP_INCOMING}"
    # get -P preserves file attributes
    echo "get -P ${UCLA_SFTP_INCOMING}/* ${FILES_INCOMING}"
  ) | sftp ${UCLA_SFTP_USER}@${UCLA_SFTP_SERVER} 2>/dev/null

  # Log info about incoming files
  find ${FILES_INCOMING} -type f | while read ETD; do
    _get_proquest_id ${ETD}
    _log_message ${PROQUEST_ID} ${STATUS_RETRIEVED} "Retrieved `basename ${ETD}`"
  done
}

###########################################################################
# Get ProQuest id from filename inside zipped ETD
# Use before initial file has been unzipped and deleted.
# Sets ${PROQUEST_ID} for caller to use.
_get_proquest_id() {
  ETD=$1
  # Each ETD should contain only one *_DATA.xml file, for example:
  # Lucero_ucla_0031D_14054_DATA.xml
  # The ProQuest id is the set of digits before _DATA.xml (the 4th field).
  # To be safest, take the first matching line, and look for 5+ digits in the 4th field.
  PROQUEST_ID=`
    unzip -Z -1 ${ETD} *_DATA.xml | \
    head -1 | \
    cut -d_ -f4 | \
    grep "^[0-9]\{5,\}"
    `
  if [ -z "${PROQUEST_ID}" ]; then
    # Set default invalid value to make database happy
    PROQUEST_ID=0
    _log_error ${PROQUEST_ID} "Could not get ProQuest id from file ${ETD}"
  fi
}

###########################################################################
# Check database for duplicate ProQuest id and return number of times it exists.
# Bash return values: 0 = success, non-0 = error.
_is_id_unique() {
  PROQUEST_ID=$1
  OCCURRENCES=0
  if [ ${PROQUEST_ID} -ne 0 ]; then
    SQL="select count(*) from etd_metadata where proquest_id = '$1'"
    OCCURRENCES=`sqlite3 ${DB} "${SQL}"`
  fi
  return ${OCCURRENCES}
}

###########################################################################
# Unzip ETD archive into subdirectory named for ProQuest id
_unzip_archive() {
  ETD=$1
  _get_proquest_id ${ETD}
  if [ ${PROQUEST_ID} -ne 0 ]; then
    # If target directory already exists, exit function with error
    TARGET=${FILES_PENDING}/${PROQUEST_ID}
    if [ -d ${TARGET} ]; then
      _log_error ${PROQUEST_ID} "Target directory ${TARGET} already exists"
      return 1
    else
      TARGET_DIR=${FILES_PENDING}/${PROQUEST_ID}
	  # Unzip, never overwriting files
      unzip -q -n ${ETD} -d ${TARGET_DIR}
      RETURN_CODE=$?
      if [ ${RETURN_CODE} -eq 0 ]; then
        _log_message ${PROQUEST_ID} ${STATUS_UNZIPPED} "Unzipped to ${TARGET_DIR}"
        # Unzip succeeded, so delete original ETD zip file once we're done with it
        _log_etd_metadata ${ETD}
        # TODO: On success, should also delete original ETD from UCLA_SFTP_INCOMING
        _DEBUG "Archiving ${ETD}"
        mv ${ETD} ${FILES_ARCHIVE}
        # TODO: Use sftp batch mode for better error handling?
        SFTP_ETD=`basename ${ETD}`
        _DEBUG "Deleting ${UCLA_SFTP_INCOMING}/${SFTP_ETD}"
        echo "rm ${UCLA_SFTP_INCOMING}/${SFTP_ETD}" | sftp ${UCLA_SFTP_USER}@${UCLA_SFTP_SERVER}
      else
        _log_error ${PROQUEST_ID} "Non-zero return code ${RETURN_CODE} unzipping ${ETD}"
      fi
      # ETD zip files from ProQuest have undesirable perms on contents: 666 for files, 755 for subdirs.
      # umask doesn't affect this, as PQ's zip files have permissions embedded, so
      # reset permissions after unzipping.
      chmod -R g+w,o-rwx ${TARGET_DIR}
    fi
  fi
}

###########################################################################
# Upload unpacked ETD archives to sftp server for Graduate Division.
# They don't like zip files so we send them the unpacked version.
# Solaris sftp client is primitive - no -r recursion - and our sftp server
# currently does not allow scp/rsync - see MAINT-1613.
# Can't mput due to occasional subdirectories.
# TODO: Replace convoluted upload with one-liner if/when things improve.
_send_files_to_graddiv() {
  PROQUEST_ID=$1
  # Check for required status before proceeding
  if _has_status ${PROQUEST_ID} ${STATUS_UNZIPPED}; then
    SOURCE_DIR=${FILES_PENDING}/${PROQUEST_ID}
    TARGET_DIR=${UCLA_SFTP_GRADDIV}/${PROQUEST_ID}
    SFTP_SCRIPT=/tmp/etd_sftp_to_graddiv.$$
    rm -f ${SFTP_SCRIPT}
    if [ -d ${SOURCE_DIR} ]; then
      find ${SOURCE_DIR} | while read ENTRY; do
        # Strip off path before the ProQuest ID
        TARGET=`echo "${ENTRY}" | sed "s#${FILES_PENDING}/##"`
        TARGET="${UCLA_SFTP_GRADDIV}/${TARGET}"
        # Upload each to sftp server, creating directories/files as needed
        if [ -d "${ENTRY}" ]; then
          echo "mkdir ${TARGET}" >> ${SFTP_SCRIPT}
        elif [ -f "${ENTRY}" ]; then
          echo "put \"${ENTRY}\" \"${TARGET}\"" >> ${SFTP_SCRIPT}
        fi
      done # find SOURCE_DIR
      # Use sftp's batch mode, for better error handling.
      # First command is directory creation; if that fails, whole script fails.
      sftp -b ${SFTP_SCRIPT} ${UCLA_SFTP_USER}@${UCLA_SFTP_SERVER}
      RETURN_CODE=$?
      if [ ${RETURN_CODE} -ne 0 ]; then
        _log_error ${PROQUEST_ID} "Unable to upload to ${TARGET_DIR}"
      else
        _log_message ${PROQUEST_ID} ${STATUS_GRADDIV} "Uploaded to Graduate Division"
      fi
      rm ${SFTP_SCRIPT}
    fi # ${SOURCE_DIR}
  fi # _has_status
}

###########################################################################
# Get name of DATA xml file from unzipped ETD
# Sets ${XML} for caller to use.
_get_etd_xml() {
  PROQUEST_ID=$1
  # Should only be one *_DATA.xml but limit to first one to be safe
  XML=`find ${FILES_PENDING}/${PROQUEST_ID} -name "*_DATA.xml" | head -1`
  if [ -z "${XML}" ]; then
    _log_error ${PROQUEST_ID} "Unable to find XML file for ProQuest ID ${PROQUEST_ID}"
  fi
}

###########################################################################
# Capture selected metadata from XML to database.
_log_etd_metadata() {
  ETD=$1
  _get_proquest_id ${ETD}
  _get_etd_xml ${PROQUEST_ID}
  if [ -r ${XML} ]; then
    DATA=`\
    ${JAVA} -cp "${CLASSPATH}" ${TAG_FINDER} \
      ${XML} \
      DISS_surname DISS_fname DISS_title \
      DISS_degree DISS_inst_contact DISS_cat_desc \
      DISS_accept_date DISS_submission@embargo_code \
      DISS_agreement_decision_date DISS_sales_restriction@remove DISS_delayed_release \
    `
    # RHEL doesn't have -E flag for ls, like Solaris
    ETD_DATE=`ls -l --time-style=long-iso ${ETD} | awk '{print $6}'`
    ETD_NAME=`basename ${ETD}`

    # Split tab-delimited ${DATA} into individual fields for database insert
    IFS=$'\t' read -r AUTHOR_SURNAME AUTHOR_FIRSTNAME TITLE DEGREE INSTITUTIONAL_CONTACT CATEGORY PROQUEST_ACCEPT_DATE EMBARGO_CODE AGREEMENT_DECISION_DATE SALES_RESTRICTION_DATE DELAYED_RELEASE_DATE <<< "${DATA}"
    # Insert the data
    SQL="insert into etd_metadata (proquest_id, etd_filename, etd_filedate, author_surname, author_firstname, title, degree, institutional_contact, category, proquest_accept_date, embargo_code, agreement_decision_date, sales_restriction_date, delayed_release_date) values ('${PROQUEST_ID}', '${ETD_NAME}', '${ETD_DATE}', '${AUTHOR_SURNAME}', '${AUTHOR_FIRSTNAME}', '${TITLE}', '${DEGREE}', '${INSTITUTIONAL_CONTACT}', '${CATEGORY}', '${PROQUEST_ACCEPT_DATE}', '${EMBARGO_CODE}', '${AGREEMENT_DECISION_DATE}', '${SALES_RESTRICTION_DATE}', '${DELAYED_RELEASE_DATE}')"
    sqlite3 ${DB} --cmd ".mode tabs" "${SQL}"
  fi
}

###########################################################################
# Get embargo code from XML
# Sets ${EMBARGO_CODE} for caller to use.
_get_embargo_code() {
  PROQUEST_ID=$1
  _get_etd_xml ${PROQUEST_ID}
  EMBARGO_CODE=
  if [ -r ${XML} ]; then
    EMBARGO_CODE=`${JAVA} -cp "${CLASSPATH}" ${TAG_FINDER} ${XML} DISS_submission@embargo_code`
  fi
  _DEBUG "Embargo code: ${EMBARGO_CODE}"
}

###########################################################################
# Get UCLA acceptance date from Graduate Division
_get_ucla_acceptance_date() {
  PROQUEST_ID=$1
  if _has_status ${PROQUEST_ID} ${STATUS_ACCEPTED}; then
    # No action - can't negate the _has_status function call for some reason, so use "empty" statement colon
    :
  else
    UCLA_ACCEPT_DATE=`python ${GRAD_SERVICE_CLIENT} ${GRAD_SERVICE_KEY} ${PROQUEST_ID}`
    if [ "${UCLA_ACCEPT_DATE}" ]; then
      _log_message ${PROQUEST_ID} ${STATUS_ACCEPTED} "UCLA acceptance date: ${UCLA_ACCEPT_DATE}"
      _log_ucla_dates ${PROQUEST_ID} "${UCLA_ACCEPT_DATE}"
    else
      _log_error ${PROQUEST_ID} "No UCLA acceptance date from Graduate Division"
    fi
  fi
  _DEBUG "UCLA Acceptance date: ${UCLA_ACCEPT_DATE}"
}

###########################################################################
# Capture UCLA acceptance and release dates to database.
# Per ETD-94, no longer sending UCLA release date to CDL, so set it to be the same
# as UCLA acceptance date for logging / avoid changes to etd_metadata table.
_log_ucla_dates() {
  PROQUEST_ID=$1
  UCLA_ACCEPT_DATE=$2
  UCLA_RELEASE_DATE=${UCLA_ACCEPT_DATE}
  _DEBUG "${PROQUEST_ID} ***** ${UCLA_ACCEPT_DATE} ***** ${UCLA_RELEASE_DATE}"
  # Add these dates to the database
  SQL="update etd_metadata set ucla_accept_date = '$2', ucla_release_date = '$2' where proquest_id = '$1';"
  sqlite3 ${DB} "${SQL}"
}

###########################################################################
# Update ETD XML metadata with embargo code and dates.
# Requires: XML and UCLA_ACCEPT_DATE.
_update_etd_xml() {
  PROQUEST_ID=$1
  _get_etd_xml ${PROQUEST_ID}
  _get_ucla_acceptance_date ${PROQUEST_ID}

  if [ "${UCLA_ACCEPT_DATE}" ]; then
    # Java program will throw meaningful error if XML not found or not readable/writeable, so no extra test here.
    # Make backup of XML first - while testing at least
    if _DEBUG_MODE; then cp -p ${XML} ${XML}.bak; fi
    ${JAVA} -cp "${CLASSPATH}" ${ETD_METADATA_UPDATER} ${XML} "${UCLA_ACCEPT_DATE}"
    RETURN_CODE=$?
    if [ ${RETURN_CODE} -eq 0 ]; then
      _log_message ${PROQUEST_ID} ${STATUS_XML_UPDATED} "Updated XML file ${XML}"
      _DEBUG "XML changes"
      if _DEBUG_MODE; then 
        diff -U0 ${XML}.bak ${XML}
        rm ${XML}.bak
      fi
    else
      _log_error ${PROQUEST_ID} "Could not update ${XML}: error code ${RETURN_CODE}, acceptance date ${UCLA_ACCEPT_DATE}"
    fi
  fi
}

###########################################################################
# Write Meritt Electronic Resource Citation file
# Needs to be called after _update_etd_xml as it uses the updated acceptance date.
_write_erc_file() {
  PROQUEST_ID=$1
  # Check for required status before proceeding
  if _has_status ${PROQUEST_ID} ${STATUS_XML_UPDATED}; then
    _get_etd_xml ${PROQUEST_ID}
    if [ -r ${XML} ]; then
      ETD_DIR=`dirname ${XML}`
      # ERC_FILE_WRITER requires trailing slash on ETD_DIR
      ${JAVA} -cp "${CLASSPATH}" ${ERC_FILE_WRITER} ${XML} ${ETD_DIR}/
      # Make sure file was created
      ERC_FILE=${ETD_DIR}/mrt-erc.txt
      if [ -s ${ERC_FILE} ]; then
        _log_message ${PROQUEST_ID} ${STATUS_ERC} "Created ERC file ${ERC_FILE}"
        _DEBUG "Checking ERC file contents"
        cat ${ERC_FILE}
      else
        _log_error ${PROQUEST_ID} "Unable to create ERC file ${ERC_FILE}"
      fi
    else
      _log_error ${PROQUEST_ID} "Unable to read XML file to create ERC file ${ERC_FILE}"
    fi # ${XML}
  fi # _has_status
}

###########################################################################
# Create zip file of modified ETD for Merritt
_create_zip_for_merritt() {
  PROQUEST_ID=$1
  # Check for required status before proceeding
  if _has_status ${PROQUEST_ID} ${STATUS_ERC}; then
    ETD=${FILES_PENDING}/${PROQUEST_ID}
    ZIP_FILE=/tmp/${PROQUEST_ID}.zip
    # Do not keep paths in zip file
    zip -9jqr ${ZIP_FILE} ${ETD}
    RETURN_CODE=$?
    if [ ${RETURN_CODE} -eq 0 ]; then
      _log_message ${PROQUEST_ID} ${STATUS_ZIPPED} "Zipped new archive for Merritt: ${ZIP_FILE}"
    else
      _log_error ${PROQUEST_ID} "Non-zero return code ${RETURN_CODE} zipping file for Merritt: ${ZIP_FILE}"
    fi
    _DEBUG "Check zip contents..."
    if _DEBUG_MODE; then unzip -l ${ZIP_FILE}; fi
  fi
}

###########################################################################
# Upload modified ETD zip file to CDL for Merritt
_upload_to_cdl() {
  PROQUEST_ID=$1
  # Check for required status before proceeding
  if _has_status ${PROQUEST_ID} ${STATUS_ZIPPED}; then
    # _create_zip_for_merritt should have created /tmp/PROQUEST_ID.zip
    ZIP_FILE=/tmp/${PROQUEST_ID}.zip
    if [ -s ${ZIP_FILE} ]; then
      # TODO: Use sftp batch mode for better error handling?
      echo "put ${ZIP_FILE} ${CDL_SFTP_ETD_DIR}" | sftp ${CDL_SFTP_USER}@${CDL_SFTP_SERVER}
      # This assumes success, which is bad...
      _log_message ${PROQUEST_ID} ${STATUS_TO_CDL} "Uploaded ETD to CDL for Merritt: ${ZIP_FILE}"
      _send_status_by_email ${PROQUEST_ID}
      _DEBUG "Deleting zip file ${ZIP_FILE}..."
      rm ${ZIP_FILE}
    fi
  fi
}

###########################################################################
# Retrieve MARC records from CDL
_get_marc_records_from_cdl() {
  # Retrieve all MARC files
  # TODO: Use sftp batch mode for better error handling?
  _DEBUG "Retrieving MARC records from CDL..."
  (
    echo "get -P ${CDL_SFTP_MARC_DIR}/*.mrc ${MARC_INCOMING}" 
    echo "rm ${CDL_SFTP_MARC_DIR}/*.mrc"
  ) | sftp ${CDL_SFTP_USER}@${CDL_SFTP_SERVER} 2>/dev/null
  # umask (set in _initialize) doesn't seem to help here, so fix permissions on these new files.
  # chmod complains if no files, so quick test for existence
  if ls ${MARC_INCOMING}/* > /dev/null 2>&1; then
    chmod g+w ${MARC_INCOMING}/*
  else
    echo "NO FILES"
  fi
}

###########################################################################
# Load MARC records from CDL
_load_marc_records() {
  # Assumes MARC_INCOMING has no subdirectories (it shouldn't); no -maxdepth in Solaris find
  ls -1 ${MARC_INCOMING}/*.mrc 2>/dev/null | while read MARC_FILE; do
    # vger_bulkimport_file puts logs in current directory
    cd ${MARC_INCOMING}
    _DEBUG "Loading ${MARC_FILE} into Voyager..."
    ${VGER_SCRIPT}/vger_bulkimport_file ${MARC_FILE} ucladb ETDCDL
    # Get filename without directory, so we can match it with the log
    MARC_BASE_FILENAME=`basename ${MARC_FILE}`
    mv *${MARC_BASE_FILENAME}* ${MARC_ARCHIVE}
  done
}

###########################################################################
# Update MARC status information
_update_marc_status() {
  _DEBUG "Updating MARC status..."
  SQL_SCRIPT=${SQL_BASE}/etd_link_to_voyager.sql
  # Suppress output from vger_sqlplus_run
  ${VGER_SCRIPT}/vger_sqlplus_run ${SCHEMA} ${SQL_SCRIPT} > /dev/null
  # Include output from sql script in this script's output
  cat ${SQL_SCRIPT}.out
  rm ${SQL_SCRIPT}.out
}

###########################################################################
# Delete ETDs older than retention policy
_delete_old_etds() {
  # Use archive file date to determine age
  find ${FILES_ARCHIVE} -type f -name "etdadmin*.zip" -mtime +${DAYS_TO_KEEP} | while read ETD; do
    _get_proquest_id ${ETD}
    _DEBUG "Deleting old files for ${PROQUEST_ID}..."
    if _has_status ${PROQUEST_ID} ${STATUS_TO_CDL}
    then
      # Delete the zip archive file
      _DEBUG "  Deleting ${ETD}"
      rm ${ETD}
      # Delete the unzipped files
      if [ -d ${FILES_PENDING}/${PROQUEST_ID} ]; then
        _DEBUG "  Deleting ${FILES_PENDING}/${PROQUEST_ID}"
        rm -r ${FILES_PENDING}/${PROQUEST_ID}
      else
        _DEBUG "  Not found: ${FILES_PENDING}/${PROQUEST_ID}"
      fi
      # Delete graddiv copy from SFTP
      _delete_from_graddiv ${PROQUEST_ID}
    else
      # TODO: Make this a logged error, after cleanup is done
      _DEBUG "  WARNING: ${PROQUEST_ID} does not have status supporting deletion"
    fi # _has_status
  done
}

###########################################################################
# Delete ETDs from Graduate Division directory on our SFTP server
_delete_from_graddiv() {
  PROQUEST_ID=$1
  TARGET=${UCLA_SFTP_GRADDIV}/${PROQUEST_ID}
  _DEBUG "Deleting ${TARGET}"
  # Our SFTP client/server doesn't support rm -rf so have to check for
  # subdirectories, remove files/subdirs if they exist, then the main dir.
  # sftp client prints echoes all commands; we don't care if the directories
  # don't exist, so ignore the output.
  SUBDIR=`echo "ls -l ${TARGET}" | sftp ${UCLA_SFTP_USER}@${UCLA_SFTP_SERVER} 2>/dev/null | tail -n +4 | grep "^d" | awk '{print $9}'`
  (
    if [ -n "${SUBDIR}" ]; then
      echo "rm ${TARGET}/${SUBDIR}/*"
      echo "rmdir ${TARGET}/${SUBDIR}"
    fi

    echo "rm ${TARGET}/*"
    echo "rmdir ${TARGET}"
  ) | sftp ${UCLA_SFTP_USER}@${UCLA_SFTP_SERVER} > /dev/null 2>&1
}

###########################################################################
# Send email with status info about a given ProQuest ID
# TODO: If needed, make this more generic
_send_status_by_email() {
  PROQUEST_ID=$1
  SQL="select * from etd_status where proquest_id = '$1' order by status_date"
  # Pipe output through tr to strip characters Exchange doesn't like in email...
  sqlite3 ${DB} "${SQL}" | tr -cd '\11\12\40-\176' | mailx -s "ProQuest ETD ${PROQUEST_ID} status info" "${EMAIL_RECIPIENTS}"
}

###########################################################################
# Get list of ProQuest IDs with a particular status
_get_ids_by_status() {
  STATUS=$1
  SQL="select proquest_id from etd_status s where status = '$1' and status_date = (select max(status_date) from etd_status where proquest_id = s.proquest_id) order by proquest_id"
  sqlite3 ${DB} "${SQL}"
}

###########################################################################
# Check whether an ETD has a particular status
# TODO: Compare with _log_message, be consistent with explicit vs. var for sql script name.
_has_status() {
  PROQUEST_ID=$1
  STATUS=$2
  SQL="select case when count(*) = 0 then 'false' else 'true' end from etd_status where proquest_id = '$1' and status = '$2'"
  # SQL output is either "true" or "false"; capture grep exit code and return that to caller.
  sqlite3 ${DB} "${SQL}" | grep "true" > /dev/null
  FOUND=$?
  return ${FOUND}
}

###########################################################################
# Write messages to log
_log_message() {
  ID=$1
  STATUS=$2
  MESSAGE=$3
  _DEBUG "${ID} ***** ${STATUS} ***** ${MESSAGE}"
  SQL="insert into etd_status (proquest_id, status, message) values ('$1', '$2', '$3');"
  sqlite3 ${DB} "${SQL}"
}

###########################################################################
# Decorate error messages before logging
_log_error() {
  ID=$1
  MESSAGE=$2
  STATUS=${STATUS_ERROR}
  _log_message ${ID} ${STATUS} "${MESSAGE}"

  # Also send email for immediate alert
  echo "${MESSAGE}" | mailx -s "ERROR processing ETD ${ID}" "${EMAIL_RECIPIENTS}"
}

###########################################################################
# Convenience function for debugging
_DEBUG_MODE() {
  if [ ${DEBUG_FLAG} = TRUE ]; then
    return 0
  else
    return 1
  fi
}

###########################################################################
# Print debugging message
_DEBUG() {
  if _DEBUG_MODE; then
    echo "DEBUG: $1"
  fi
}

###########################################################################
# Put test code here
_TEST() {
#  _TEST_CLEANUP
  ETD=${FILES_ARCHIVE}/etdadmin_upload_944157.zip
  PROQUEST_ID=21345
#   if _has_status ${PROQUEST_ID} ${STATUS_UNZIPPED}; then
#     echo "oracle: ${PROQUEST_ID} is unzipped"
#   fi
#   if _has_status_lite ${PROQUEST_ID} ${STATUS_UNZIPPED}; then
#     echo "sqlite: ${PROQUEST_ID} is unzipped"
#   fi

#   if _has_status ${PROQUEST_ID} ${STATUS_ERROR}; then
#     echo "oracle: ${PROQUEST_ID} has error"
#   else
#     echo "oracle: ${PROQUEST_ID} has no errors"
#   fi
#   if _has_status_lite ${PROQUEST_ID} ${STATUS_ERROR}; then
#     echo "sqlite: ${PROQUEST_ID} has error"
#   else
#     echo "sqlite: ${PROQUEST_ID} has no errors"
#   fi

#   _log_message 99999 TESTING "This is a test message"
  _log_etd_metadata ${ETD}

  UCLA_ACCEPT_DATE=`python ${GRAD_SERVICE_CLIENT} ${GRAD_SERVICE_KEY} ${PROQUEST_ID}`
  if [ "${UCLA_ACCEPT_DATE}" ]; then
    _log_message ${PROQUEST_ID} ${STATUS_ACCEPTED} "UCLA acceptance date: ${UCLA_ACCEPT_DATE}"
    _log_ucla_dates ${PROQUEST_ID} "${UCLA_ACCEPT_DATE}"
  else
    _log_error ${PROQUEST_ID} "No UCLA acceptance date from Graduate Division"
  fi
  _send_status_by_email ${PROQUEST_ID}
}

###########################################################################
# Run sql script for testing only
_TEST_RUN_SQL() {
  SQL_SCRIPT=$1
  ${VGER_SCRIPT}/vger_sqlplus_run ${SCHEMA} ${SQL_SCRIPT}
  cat ${SQL_SCRIPT}.out
  rm ${SQL_SCRIPT}.out
}

###########################################################################
# Clean up from testing
_TEST_CLEANUP() {
  rm -rf ${FILES_PENDING}/*
  rm -rf ${FILES_INCOMING}/etdadmin*.zip
  sftp -b ${BASE}/test/TEST_clean_graddiv ${UCLA_SFTP_USER}@${UCLA_SFTP_SERVER}
  _TEST_RUN_SQL ${TEST_BASE}/TEST_clean_etd_status.sql
}

###########################################################################
# Phase 1: Retrieve ETDs, unzip, deliver to Grad Div
_phase_1() {
  _DEBUG "Phase 1"
  _get_incoming_files
  # Do initial processing of each new archive
  find ${FILES_INCOMING} -type f -name "etdadmin*.zip" | while read ETD; do
    # Need to get ProQuest ID before deleting zip file after unzipping
    _get_proquest_id ${ETD}
    if _is_id_unique ${PROQUEST_ID}; then
      # Return value 0: unique, so continue processing
      _unzip_archive ${ETD}
      _send_files_to_graddiv ${PROQUEST_ID}
    else
      # Return value non-0: duplicate, so log error
      _log_error ${PROQUEST_ID} "Incoming ETD ${ETD}: ProQuest ID ${PROQUEST_ID} already exists"
    fi
  done
}

###########################################################################
# Phase 2: Update ETD, deliver to CDL
_phase_2() {
  _DEBUG "Phase 2"
  # Act on ETDs which have been sent to GradDiv
  _get_ids_by_status ${STATUS_GRADDIV} | while read PROQUEST_ID; do
    _update_etd_xml ${PROQUEST_ID}
    _write_erc_file ${PROQUEST_ID}
    _create_zip_for_merritt ${PROQUEST_ID}
    _upload_to_cdl ${PROQUEST_ID}
  done
}

###########################################################################
# Phase 3: Retrieve MARC records from CDL and load into Voyager
_phase_3() {
  _DEBUG "Phase 3: MARC records no longer loaded here"
  ### MARC records from CDL now go by email to catalogers for loading into Alma 2021-11-02 akohler
  ### _get_marc_records_from_cdl
  ### MARC load disabled now that Voyager is read-only 2021-10-27 akohler
  ### _load_marc_records
  ### _update_marc_status
}

###########################################################################
# Phase 4: Remove old ETDs per retention policy
_phase_4() {
  _DEBUG "Phase 4"
  _delete_old_etds
}

###########################################################################
# Main routine starts here.
_exit_if_already_running
_initialize

# TODO: Controller to handle command-line arguments
_phase_1
_phase_2
_phase_3
_phase_4
echo "Finished processing: `date`"
#_TEST
